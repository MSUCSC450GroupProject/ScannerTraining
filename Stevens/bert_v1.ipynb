{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                                         NC and NH.      0\n",
       "1  You do know west teams play against west teams...      0\n",
       "2  They were underdogs earlier today, but since G...      0\n",
       "3  This meme isn't funny none of the \"new york ni...      0\n",
       "4                    I could use one of those tools.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training dataframe\n",
    "sarc_train = pd.read_csv(\"../shared_data/train-balanced-sarcasm.csv\")\n",
    "\n",
    "# Drop rows with null values\n",
    "sarc_train = sarc_train.dropna()\n",
    "# isolate comments and rows\n",
    "sarc_train = sarc_train[['label', 'comment']]\n",
    "# rename columns and reindex\n",
    "sarc_train = sarc_train.rename(columns ={'comment':'text'})\n",
    "sarc_train = sarc_train.reindex(columns=['text','label'])\n",
    "# peek at the data\n",
    "sarc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1010773 entries, 0 to 1010825\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   text    1010773 non-null  object\n",
      " 1   label   1010773 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 23.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# we should see that there are only rows with non-null values\n",
    "sarc_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = len(sarc_train.index)\n",
    "testing_size = int(subset_size * 0.4)\n",
    "validation_size = int(subset_size * 0.2)\n",
    "shuffle_size = subset_size - validation_size\n",
    "\n",
    "data_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sarc_train.sample(frac=1).reset_index(drop=True)\n",
    "train_data = data.head(subset_size)\n",
    "test_data = data.tail(testing_size)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        train_data['text'][validation_size:], \n",
    "        train_data['label'][validation_size:]\n",
    "    )\n",
    ").shuffle(shuffle_size).batch(data_batch_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        train_data['text'][:validation_size],\n",
    "        train_data['label'][:validation_size]\n",
    "    )\n",
    ").batch(data_batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        test_data['text'],\n",
    "        test_data['label']\n",
    "    )\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "init_lr = 3e-5\n",
    "\n",
    "#define the parameters for tokenizing and padding\n",
    "vocab_size = 10000\n",
    "embedding_dim = 32\n",
    "max_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "preprocessing_layer = hub.KerasLayer(\n",
    "    'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', \n",
    "    name='preprocessing'\n",
    ")\n",
    "\n",
    "bert_encoder = hub.KerasLayer(\n",
    "    'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1', \n",
    "    trainable=True, \n",
    "    name='BERT_encoder'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    outputs = bert_encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25270/25270 [==============================] - ETA: 0s - loss: 0.5602 - binary_accuracy: 0.6956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25270/25270 [==============================] - 6025s 238ms/step - loss: 0.5602 - binary_accuracy: 0.6956 - val_loss: 0.5201 - val_binary_accuracy: 0.7454\n",
      "Epoch 2/10\n",
      "25270/25270 [==============================] - ETA: 0s - loss: 0.4959 - binary_accuracy: 0.7474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25270/25270 [==============================] - 6112s 242ms/step - loss: 0.4959 - binary_accuracy: 0.7474 - val_loss: 0.4974 - val_binary_accuracy: 0.7456\n",
      "Epoch 3/10\n",
      "25270/25270 [==============================] - ETA: 0s - loss: 0.4576 - binary_accuracy: 0.7742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25270/25270 [==============================] - 6214s 246ms/step - loss: 0.4576 - binary_accuracy: 0.7742 - val_loss: 0.4937 - val_binary_accuracy: 0.7515\n",
      "Epoch 4/10\n",
      "25270/25270 [==============================] - ETA: 0s - loss: 0.4205 - binary_accuracy: 0.7992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25270/25270 [==============================] - 6127s 242ms/step - loss: 0.4205 - binary_accuracy: 0.7992 - val_loss: 0.5061 - val_binary_accuracy: 0.7576\n",
      "Epoch 5/10\n",
      "25270/25270 [==============================] - ETA: 0s - loss: 0.3834 - binary_accuracy: 0.8225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_saves/bert_v0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25270/25270 [==============================] - 6090s 241ms/step - loss: 0.3834 - binary_accuracy: 0.8225 - val_loss: 0.5421 - val_binary_accuracy: 0.7596\n",
      "Epoch 6/10\n",
      "25270/25270 [==============================] - 5951s 235ms/step - loss: 0.3469 - binary_accuracy: 0.8439 - val_loss: 0.5739 - val_binary_accuracy: 0.7567\n",
      "Epoch 7/10\n",
      "25270/25270 [==============================] - 5910s 234ms/step - loss: 0.3151 - binary_accuracy: 0.8613 - val_loss: 0.6155 - val_binary_accuracy: 0.7555\n",
      "Epoch 8/10\n",
      "25270/25270 [==============================] - 5912s 234ms/step - loss: 0.2870 - binary_accuracy: 0.8758 - val_loss: 0.6602 - val_binary_accuracy: 0.7536\n",
      "Epoch 9/10\n",
      "25270/25270 [==============================] - 5917s 234ms/step - loss: 0.2655 - binary_accuracy: 0.8870 - val_loss: 0.7135 - val_binary_accuracy: 0.7513\n",
      "Epoch 10/10\n",
      "25270/25270 [==============================] - 5948s 235ms/step - loss: 0.2493 - binary_accuracy: 0.8951 - val_loss: 0.7299 - val_binary_accuracy: 0.7512\n",
      "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n",
      "12635/12635 [==============================] - 1296s 103ms/step - loss: 0.1597 - binary_accuracy: 0.9393\n",
      "Loss: 0.15965259075164795\n",
      "Accuracy: 0.9392815828323364\n"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "optimizer = optimization.create_optimizer(\n",
    "    init_lr=init_lr,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    optimizer_type='adamw'\n",
    ")\n",
    "\n",
    "classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "saved_model_path = './model_saves/bert_v0/'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=saved_model_path,\n",
    "    monitor='val_binary_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs,\n",
    "                               callbacks=[checkpoint])\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "### Test the model\n",
    "loss, accuracy = classifier_model.evaluate(test_ds.batch(data_batch_size))\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('learn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9e883898f11bad5bc8c5923140b2d92d0deffd021fd4a7ef267896d2a9b7543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
