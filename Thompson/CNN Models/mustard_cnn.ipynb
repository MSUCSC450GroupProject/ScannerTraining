{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the tensorflow APIs\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>And of those few months, how long have you bee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Let the dead man talk. So, why do you think that?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What else? Sell it on eBay as \"slightly used.\"</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Good idea, sit with her. Hold her, comfort her...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Well, now that I've given up string theory, I'...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "5   And of those few months, how long have you bee...    0.0\n",
       "14  Let the dead man talk. So, why do you think that?    0.0\n",
       "18     What else? Sell it on eBay as \"slightly used.\"    0.0\n",
       "24  Good idea, sit with her. Hold her, comfort her...    1.0\n",
       "31  Well, now that I've given up string theory, I'...    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sitcoms = pd.read_csv(\"mustard++_text.csv\")\n",
    "\n",
    "# Adjust sitcom data\n",
    "data_sitcoms = data_sitcoms.drop(columns=['SCENE','KEY','END_TIME','SPEAKER','SHOW','Sarcasm_Type','Implicit_Emotion','Explicit_Emotion','Valence','Arousal'], axis=1)\n",
    "data_sitcoms = data_sitcoms.rename(columns={'SENTENCE':'text','Sarcasm':'label'})\n",
    "\n",
    "# remove empty label rows\n",
    "for index, row in data_sitcoms.iterrows():\n",
    "    if math.isnan(row['label']):\n",
    "        data_sitcoms = data_sitcoms.drop(index, axis='index')\n",
    "\n",
    "data_sitcoms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1202 entries, 5 to 6040\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   text    1202 non-null   object \n",
      " 1   label   1202 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 28.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_sitcoms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = data_sitcoms[\"text\"]\n",
    "##train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##instantiate the tokenizer\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "\n",
    "##train the tokenizer on training sentences\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "##store word index for the words in the sentence\n",
    "word_index = tokenizer.word_index\n",
    "##print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create sequences using tokenizer\n",
    "sequences = tokenizer.texts_to_sequences(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print word index dictionary and sequences\n",
    "##print(f\"Word index -->{word_index}\")\n",
    "##print(f\"Sequences of words -->{sequences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print sample sentence and sequence\n",
    "train_sentences = train_sentences.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I guess the sad truth is, not everyone will accomplish something great. Some of us may just have to find meaning in the little moments that make up life.\n",
      "[6, 8, 50, 24, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[random.randint(0,100)])\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##set up the tokenizer again with oov_token\n",
    "tokenizer = Tokenizer(num_words=100, oov_token = \"<oov>\")\n",
    "\n",
    "##train the new tokenizer on training sentences\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "##store word index for the words in the sentence\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pad sequences\n",
    "padded_seqs = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print(word_index)\n",
    "##print(train_sentences)\n",
    "##print(sequences)\n",
    "##print(padded_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  8 50 24  1]\n",
      " [ 3 29 59 27  1]\n",
      " [23  7 17 58  0]\n",
      " ...\n",
      " [31 72 89 67 42]\n",
      " [ 2  9 16  3  0]\n",
      " [ 9 42 57  0  0]]\n"
     ]
    }
   ],
   "source": [
    "##pad sequences with padding type, max length and truncating parameters\n",
    "padded_seqs = pad_sequences(sequences,\n",
    "                            padding=\"post\",\n",
    "                            maxlen=5,\n",
    "                            truncating=\"post\",\n",
    "                            )\n",
    "print(padded_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create empty list to store sentences and labels\n",
    "train_sentences = []\n",
    "test_sentences = []\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create size variables to for training\n",
    "subset_size = len(data_sitcoms.index)\n",
    "testing_size = int(subset_size * 0.2)\n",
    "validation_size = testing_size\n",
    "shuffle_size = subset_size - validation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_sitcoms.sample(frac=1).reset_index(drop=True)\n",
    "train_data = data.head(subset_size - testing_size)\n",
    "test_data = data.tail(testing_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in train_data['text']:\n",
    "    train_sentences.append(sentence)\n",
    "for sentence in test_data['text']:\n",
    "    test_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in train_data['label']:\n",
    "    train_labels.append(value)\n",
    "for value in test_data['label']:\n",
    "    test_labels.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##convert lists into numpy array\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define the parameters for the tokenizing and padding\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 16\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "##training sequences and labels\n",
    "train_seqs = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_seqs,maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "##testing sequences and labels\n",
    "test_seqs = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_seqs,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't know you and Carol were getting divorced, I'm sorry.\n",
      "[  3 155  45   2   7 517 102 228 843  14  86   0   0   0   0   0]\n",
      "i didn't know you and carol were getting divorced i'm sorry ? ? ? ? ?\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(train_sentences[1])\n",
    "print(train_padded[1])\n",
    "print(decode_review(train_padded[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Neural Network with Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 16, 16)            160000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1542      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,549\n",
      "Trainable params: 161,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "##compile the model with loss function, optimizer and metrics\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31/31 [==============================] - 1s 9ms/step - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5417\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.6775 - accuracy: 0.6476 - val_loss: 0.6941 - val_accuracy: 0.4667\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.6555 - accuracy: 0.7225 - val_loss: 0.6981 - val_accuracy: 0.4833\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.8191 - val_loss: 0.7042 - val_accuracy: 0.4792\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.8534 - val_loss: 0.7107 - val_accuracy: 0.4625\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.9012 - val_loss: 0.7238 - val_accuracy: 0.4750\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.9304 - val_loss: 0.7398 - val_accuracy: 0.4833\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.3070 - accuracy: 0.9605 - val_loss: 0.7498 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9626 - val_loss: 0.7583 - val_accuracy: 0.5250\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9771 - val_loss: 0.7764 - val_accuracy: 0.5333\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.1344 - accuracy: 0.9844 - val_loss: 0.7830 - val_accuracy: 0.5292\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9906 - val_loss: 0.8159 - val_accuracy: 0.5292\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9958 - val_loss: 0.8271 - val_accuracy: 0.5250\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9938 - val_loss: 0.8445 - val_accuracy: 0.5250\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9969 - val_loss: 0.8754 - val_accuracy: 0.5208\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.9979 - val_loss: 0.8798 - val_accuracy: 0.5292\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9979 - val_loss: 0.9044 - val_accuracy: 0.5292\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9979 - val_loss: 0.9183 - val_accuracy: 0.5250\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9979 - val_loss: 0.9331 - val_accuracy: 0.5292\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9979 - val_loss: 0.9693 - val_accuracy: 0.5292\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9979 - val_loss: 0.9680 - val_accuracy: 0.5333\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9979 - val_loss: 0.9795 - val_accuracy: 0.5333\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9979 - val_loss: 0.9936 - val_accuracy: 0.5292\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9979 - val_loss: 1.0121 - val_accuracy: 0.5250\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9979 - val_loss: 1.0416 - val_accuracy: 0.5208\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 1.0443 - val_accuracy: 0.5208\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 1.0798 - val_accuracy: 0.5125\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 1.1009 - val_accuracy: 0.5167\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 1.1014 - val_accuracy: 0.5125\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 1.1045 - val_accuracy: 0.5125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5a77bc040>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "##train the model with training and validation set\n",
    "model.fit(\n",
    "    train_padded, \n",
    "    train_labels, \n",
    "    epochs=num_epochs, \n",
    "    validation_data=(test_padded, test_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive weights from the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n",
      "[-0.02094469  0.09399135 -0.03035605  0.01968496  0.1282092   0.13088912\n",
      " -0.06012911 -0.12831557  0.11014673 -0.11737258  0.04916207  0.19115116\n",
      " -0.17397036 -0.05870754  0.00347254  0.0390837 ]\n"
     ]
    }
   ],
   "source": [
    "##isolating the first embedding layer\n",
    "l1 = model.layers[0]\n",
    "\n",
    "##extracting learned weights\n",
    "weights = l1.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
    "print(weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the vectors and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import I/O module in python\n",
    "import io\n",
    "\n",
    "##open the text stream for vectors\n",
    "vectors = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "##open the text stream for metadata\n",
    "meta = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "##write each word and its corresponding embedding\n",
    "for index in range(len(reverse_word_index)):\n",
    "  word = reverse_word_index.get(index)  # flipping the key-value in word_index\n",
    "  embeddings = weights[index]\n",
    "  if word is None:\n",
    "    break\n",
    "  else:\n",
    "    meta.write(word + \"\\n\")\n",
    "    vectors.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "\n",
    "##close the stream\n",
    "vectors.close()\n",
    "meta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download the written files to your local machine\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "  pass\n",
    "else:\n",
    "  files.download('vectors.tsv')\n",
    "  files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define tokenizing and padding parameters\n",
    "vocab_size = 10000\n",
    "max_length = 120\n",
    "embedding_dim = 16\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##store headlines and labels in respective lists\n",
    "sentences = list(data['text'])\n",
    "labels = list(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sentences\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "\n",
    "##labels\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists into numpy arrays to make it work with TensorFlow 2.x\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the neural network model with the following layers:\n",
    "1. Embedding layer\n",
    "2. Replace the bidirectional LSTM layers with convolutional layers with a filter size of 5.\n",
    "3. GlovalAveragePooling Layer to down sample the feature map.\n",
    "3. Dense layer with 24 nodes\n",
    "4. Output Dense layer with `sigmoid` activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 116, 64)           5184      \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,769\n",
      "Trainable params: 166,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "22/22 - 2s - loss: 0.6935 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.5040 - 2s/epoch - 97ms/step\n",
      "Epoch 2/300\n",
      "22/22 - 0s - loss: 0.6931 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5020 - 149ms/epoch - 7ms/step\n",
      "Epoch 3/300\n",
      "22/22 - 0s - loss: 0.6930 - accuracy: 0.5114 - val_loss: 0.6931 - val_accuracy: 0.5359 - 151ms/epoch - 7ms/step\n",
      "Epoch 4/300\n",
      "22/22 - 0s - loss: 0.6920 - accuracy: 0.5471 - val_loss: 0.6930 - val_accuracy: 0.5020 - 155ms/epoch - 7ms/step\n",
      "Epoch 5/300\n",
      "22/22 - 0s - loss: 0.6888 - accuracy: 0.6114 - val_loss: 0.6923 - val_accuracy: 0.5518 - 154ms/epoch - 7ms/step\n",
      "Epoch 6/300\n",
      "22/22 - 0s - loss: 0.6778 - accuracy: 0.7329 - val_loss: 0.6915 - val_accuracy: 0.5498 - 163ms/epoch - 7ms/step\n",
      "Epoch 7/300\n",
      "22/22 - 0s - loss: 0.6467 - accuracy: 0.7671 - val_loss: 0.6926 - val_accuracy: 0.5339 - 163ms/epoch - 7ms/step\n",
      "Epoch 8/300\n",
      "22/22 - 0s - loss: 0.5884 - accuracy: 0.7871 - val_loss: 0.7028 - val_accuracy: 0.5378 - 163ms/epoch - 7ms/step\n",
      "Epoch 9/300\n",
      "22/22 - 0s - loss: 0.5077 - accuracy: 0.8214 - val_loss: 0.7352 - val_accuracy: 0.5458 - 157ms/epoch - 7ms/step\n",
      "Epoch 10/300\n",
      "22/22 - 0s - loss: 0.4225 - accuracy: 0.8486 - val_loss: 0.7714 - val_accuracy: 0.5478 - 148ms/epoch - 7ms/step\n",
      "Epoch 11/300\n",
      "22/22 - 0s - loss: 0.3495 - accuracy: 0.8886 - val_loss: 0.8180 - val_accuracy: 0.5637 - 145ms/epoch - 7ms/step\n",
      "Epoch 12/300\n",
      "22/22 - 0s - loss: 0.2910 - accuracy: 0.9100 - val_loss: 0.8643 - val_accuracy: 0.5737 - 150ms/epoch - 7ms/step\n",
      "Epoch 13/300\n",
      "22/22 - 0s - loss: 0.2438 - accuracy: 0.9314 - val_loss: 0.9141 - val_accuracy: 0.5558 - 146ms/epoch - 7ms/step\n",
      "Epoch 14/300\n",
      "22/22 - 0s - loss: 0.2034 - accuracy: 0.9329 - val_loss: 0.9680 - val_accuracy: 0.5657 - 153ms/epoch - 7ms/step\n",
      "Epoch 15/300\n",
      "22/22 - 0s - loss: 0.1729 - accuracy: 0.9557 - val_loss: 1.0063 - val_accuracy: 0.5618 - 148ms/epoch - 7ms/step\n",
      "Epoch 16/300\n",
      "22/22 - 0s - loss: 0.1537 - accuracy: 0.9543 - val_loss: 1.0632 - val_accuracy: 0.5598 - 149ms/epoch - 7ms/step\n",
      "Epoch 17/300\n",
      "22/22 - 0s - loss: 0.1327 - accuracy: 0.9614 - val_loss: 1.0995 - val_accuracy: 0.5737 - 142ms/epoch - 6ms/step\n",
      "Epoch 18/300\n",
      "22/22 - 0s - loss: 0.1171 - accuracy: 0.9643 - val_loss: 1.1449 - val_accuracy: 0.5657 - 143ms/epoch - 7ms/step\n",
      "Epoch 19/300\n",
      "22/22 - 0s - loss: 0.1025 - accuracy: 0.9757 - val_loss: 1.1922 - val_accuracy: 0.5677 - 147ms/epoch - 7ms/step\n",
      "Epoch 20/300\n",
      "22/22 - 0s - loss: 0.0921 - accuracy: 0.9814 - val_loss: 1.2278 - val_accuracy: 0.5657 - 150ms/epoch - 7ms/step\n",
      "Epoch 21/300\n",
      "22/22 - 0s - loss: 0.0826 - accuracy: 0.9814 - val_loss: 1.2940 - val_accuracy: 0.5677 - 150ms/epoch - 7ms/step\n",
      "Epoch 22/300\n",
      "22/22 - 0s - loss: 0.0801 - accuracy: 0.9829 - val_loss: 1.3196 - val_accuracy: 0.5677 - 154ms/epoch - 7ms/step\n",
      "Epoch 23/300\n",
      "22/22 - 0s - loss: 0.0705 - accuracy: 0.9829 - val_loss: 1.3589 - val_accuracy: 0.5697 - 147ms/epoch - 7ms/step\n",
      "Epoch 24/300\n",
      "22/22 - 0s - loss: 0.0666 - accuracy: 0.9843 - val_loss: 1.3798 - val_accuracy: 0.5777 - 146ms/epoch - 7ms/step\n",
      "Epoch 25/300\n",
      "22/22 - 0s - loss: 0.0622 - accuracy: 0.9843 - val_loss: 1.4169 - val_accuracy: 0.5837 - 142ms/epoch - 6ms/step\n",
      "Epoch 26/300\n",
      "22/22 - 0s - loss: 0.0572 - accuracy: 0.9843 - val_loss: 1.4552 - val_accuracy: 0.5717 - 150ms/epoch - 7ms/step\n",
      "Epoch 27/300\n",
      "22/22 - 0s - loss: 0.0542 - accuracy: 0.9871 - val_loss: 1.4715 - val_accuracy: 0.5797 - 158ms/epoch - 7ms/step\n",
      "Epoch 28/300\n",
      "22/22 - 0s - loss: 0.0511 - accuracy: 0.9871 - val_loss: 1.5081 - val_accuracy: 0.5817 - 156ms/epoch - 7ms/step\n",
      "Epoch 29/300\n",
      "22/22 - 0s - loss: 0.0497 - accuracy: 0.9871 - val_loss: 1.5356 - val_accuracy: 0.5797 - 146ms/epoch - 7ms/step\n",
      "Epoch 30/300\n",
      "22/22 - 0s - loss: 0.0473 - accuracy: 0.9857 - val_loss: 1.5777 - val_accuracy: 0.5797 - 144ms/epoch - 7ms/step\n",
      "Epoch 31/300\n",
      "22/22 - 0s - loss: 0.0447 - accuracy: 0.9871 - val_loss: 1.6057 - val_accuracy: 0.5797 - 153ms/epoch - 7ms/step\n",
      "Epoch 32/300\n",
      "22/22 - 0s - loss: 0.0423 - accuracy: 0.9871 - val_loss: 1.6191 - val_accuracy: 0.5876 - 155ms/epoch - 7ms/step\n",
      "Epoch 33/300\n",
      "22/22 - 0s - loss: 0.0409 - accuracy: 0.9871 - val_loss: 1.6482 - val_accuracy: 0.5857 - 147ms/epoch - 7ms/step\n",
      "Epoch 34/300\n",
      "22/22 - 0s - loss: 0.0384 - accuracy: 0.9871 - val_loss: 1.6681 - val_accuracy: 0.5916 - 144ms/epoch - 7ms/step\n",
      "Epoch 35/300\n",
      "22/22 - 0s - loss: 0.0351 - accuracy: 0.9871 - val_loss: 1.6933 - val_accuracy: 0.5916 - 142ms/epoch - 6ms/step\n",
      "Epoch 36/300\n",
      "22/22 - 0s - loss: 0.0328 - accuracy: 0.9871 - val_loss: 1.7312 - val_accuracy: 0.5857 - 147ms/epoch - 7ms/step\n",
      "Epoch 37/300\n",
      "22/22 - 0s - loss: 0.0318 - accuracy: 0.9886 - val_loss: 1.7523 - val_accuracy: 0.5857 - 150ms/epoch - 7ms/step\n",
      "Epoch 38/300\n",
      "22/22 - 0s - loss: 0.0294 - accuracy: 0.9886 - val_loss: 1.7828 - val_accuracy: 0.5857 - 150ms/epoch - 7ms/step\n",
      "Epoch 39/300\n",
      "22/22 - 0s - loss: 0.0275 - accuracy: 0.9900 - val_loss: 1.8139 - val_accuracy: 0.5896 - 146ms/epoch - 7ms/step\n",
      "Epoch 40/300\n",
      "22/22 - 0s - loss: 0.0271 - accuracy: 0.9886 - val_loss: 1.8396 - val_accuracy: 0.5896 - 150ms/epoch - 7ms/step\n",
      "Epoch 41/300\n",
      "22/22 - 0s - loss: 0.0258 - accuracy: 0.9929 - val_loss: 1.8619 - val_accuracy: 0.5896 - 157ms/epoch - 7ms/step\n",
      "Epoch 42/300\n",
      "22/22 - 0s - loss: 0.0244 - accuracy: 0.9929 - val_loss: 1.8867 - val_accuracy: 0.5876 - 150ms/epoch - 7ms/step\n",
      "Epoch 43/300\n",
      "22/22 - 0s - loss: 0.0231 - accuracy: 0.9929 - val_loss: 1.9156 - val_accuracy: 0.5817 - 149ms/epoch - 7ms/step\n",
      "Epoch 44/300\n",
      "22/22 - 0s - loss: 0.0218 - accuracy: 0.9929 - val_loss: 1.9453 - val_accuracy: 0.5936 - 144ms/epoch - 7ms/step\n",
      "Epoch 45/300\n",
      "22/22 - 0s - loss: 0.0209 - accuracy: 0.9929 - val_loss: 1.9694 - val_accuracy: 0.5936 - 143ms/epoch - 6ms/step\n",
      "Epoch 46/300\n",
      "22/22 - 0s - loss: 0.0200 - accuracy: 0.9929 - val_loss: 1.9994 - val_accuracy: 0.5916 - 141ms/epoch - 6ms/step\n",
      "Epoch 47/300\n",
      "22/22 - 0s - loss: 0.0192 - accuracy: 0.9929 - val_loss: 2.0237 - val_accuracy: 0.5916 - 150ms/epoch - 7ms/step\n",
      "Epoch 48/300\n",
      "22/22 - 0s - loss: 0.0226 - accuracy: 0.9914 - val_loss: 2.1017 - val_accuracy: 0.5976 - 145ms/epoch - 7ms/step\n",
      "Epoch 49/300\n",
      "22/22 - 0s - loss: 0.0192 - accuracy: 0.9957 - val_loss: 2.0950 - val_accuracy: 0.5857 - 149ms/epoch - 7ms/step\n",
      "Epoch 50/300\n",
      "22/22 - 0s - loss: 0.0183 - accuracy: 0.9929 - val_loss: 2.1212 - val_accuracy: 0.5857 - 140ms/epoch - 6ms/step\n",
      "Epoch 51/300\n",
      "22/22 - 0s - loss: 0.0175 - accuracy: 0.9943 - val_loss: 2.1482 - val_accuracy: 0.5857 - 147ms/epoch - 7ms/step\n",
      "Epoch 52/300\n",
      "22/22 - 0s - loss: 0.0166 - accuracy: 0.9957 - val_loss: 2.1714 - val_accuracy: 0.5916 - 147ms/epoch - 7ms/step\n",
      "Epoch 53/300\n",
      "22/22 - 0s - loss: 0.0158 - accuracy: 0.9971 - val_loss: 2.1896 - val_accuracy: 0.5876 - 145ms/epoch - 7ms/step\n",
      "Epoch 54/300\n",
      "22/22 - 0s - loss: 0.0164 - accuracy: 0.9957 - val_loss: 2.2235 - val_accuracy: 0.5876 - 150ms/epoch - 7ms/step\n",
      "Epoch 55/300\n",
      "22/22 - 0s - loss: 0.0147 - accuracy: 0.9957 - val_loss: 2.2427 - val_accuracy: 0.5956 - 157ms/epoch - 7ms/step\n",
      "Epoch 56/300\n",
      "22/22 - 0s - loss: 0.0145 - accuracy: 0.9971 - val_loss: 2.2682 - val_accuracy: 0.5936 - 141ms/epoch - 6ms/step\n",
      "Epoch 57/300\n",
      "22/22 - 0s - loss: 0.0141 - accuracy: 0.9971 - val_loss: 2.2829 - val_accuracy: 0.5936 - 143ms/epoch - 6ms/step\n",
      "Epoch 58/300\n",
      "22/22 - 0s - loss: 0.0134 - accuracy: 0.9971 - val_loss: 2.3064 - val_accuracy: 0.5956 - 145ms/epoch - 7ms/step\n",
      "Epoch 59/300\n",
      "22/22 - 0s - loss: 0.0130 - accuracy: 0.9971 - val_loss: 2.3375 - val_accuracy: 0.5996 - 147ms/epoch - 7ms/step\n",
      "Epoch 60/300\n",
      "22/22 - 0s - loss: 0.0126 - accuracy: 0.9971 - val_loss: 2.3585 - val_accuracy: 0.5956 - 147ms/epoch - 7ms/step\n",
      "Epoch 61/300\n",
      "22/22 - 0s - loss: 0.0123 - accuracy: 0.9971 - val_loss: 2.3800 - val_accuracy: 0.5976 - 148ms/epoch - 7ms/step\n",
      "Epoch 62/300\n",
      "22/22 - 0s - loss: 0.0121 - accuracy: 0.9957 - val_loss: 2.3997 - val_accuracy: 0.5976 - 149ms/epoch - 7ms/step\n",
      "Epoch 63/300\n",
      "22/22 - 0s - loss: 0.0116 - accuracy: 0.9971 - val_loss: 2.4246 - val_accuracy: 0.5996 - 135ms/epoch - 6ms/step\n",
      "Epoch 64/300\n",
      "22/22 - 0s - loss: 0.0115 - accuracy: 0.9957 - val_loss: 2.4434 - val_accuracy: 0.5976 - 143ms/epoch - 7ms/step\n",
      "Epoch 65/300\n",
      "22/22 - 0s - loss: 0.0116 - accuracy: 0.9957 - val_loss: 2.4655 - val_accuracy: 0.5976 - 140ms/epoch - 6ms/step\n",
      "Epoch 66/300\n",
      "22/22 - 0s - loss: 0.0116 - accuracy: 0.9971 - val_loss: 2.4866 - val_accuracy: 0.5916 - 139ms/epoch - 6ms/step\n",
      "Epoch 67/300\n",
      "22/22 - 0s - loss: 0.0106 - accuracy: 0.9957 - val_loss: 2.5141 - val_accuracy: 0.5976 - 142ms/epoch - 6ms/step\n",
      "Epoch 68/300\n",
      "22/22 - 0s - loss: 0.0101 - accuracy: 0.9971 - val_loss: 2.5271 - val_accuracy: 0.5896 - 140ms/epoch - 6ms/step\n",
      "Epoch 69/300\n",
      "22/22 - 0s - loss: 0.0106 - accuracy: 0.9971 - val_loss: 2.5479 - val_accuracy: 0.5936 - 142ms/epoch - 6ms/step\n",
      "Epoch 70/300\n",
      "22/22 - 0s - loss: 0.0099 - accuracy: 0.9971 - val_loss: 2.5713 - val_accuracy: 0.5956 - 139ms/epoch - 6ms/step\n",
      "Epoch 71/300\n",
      "22/22 - 0s - loss: 0.0094 - accuracy: 0.9971 - val_loss: 2.5872 - val_accuracy: 0.5896 - 136ms/epoch - 6ms/step\n",
      "Epoch 72/300\n",
      "22/22 - 0s - loss: 0.0087 - accuracy: 0.9971 - val_loss: 2.6116 - val_accuracy: 0.5896 - 141ms/epoch - 6ms/step\n",
      "Epoch 73/300\n",
      "22/22 - 0s - loss: 0.0086 - accuracy: 0.9971 - val_loss: 2.6245 - val_accuracy: 0.5857 - 134ms/epoch - 6ms/step\n",
      "Epoch 74/300\n",
      "22/22 - 0s - loss: 0.0081 - accuracy: 0.9971 - val_loss: 2.6506 - val_accuracy: 0.5916 - 159ms/epoch - 7ms/step\n",
      "Epoch 75/300\n",
      "22/22 - 0s - loss: 0.0079 - accuracy: 0.9957 - val_loss: 2.6760 - val_accuracy: 0.5956 - 147ms/epoch - 7ms/step\n",
      "Epoch 76/300\n",
      "22/22 - 0s - loss: 0.0077 - accuracy: 0.9971 - val_loss: 2.6942 - val_accuracy: 0.5876 - 146ms/epoch - 7ms/step\n",
      "Epoch 77/300\n",
      "22/22 - 0s - loss: 0.0073 - accuracy: 0.9971 - val_loss: 2.7087 - val_accuracy: 0.5857 - 146ms/epoch - 7ms/step\n",
      "Epoch 78/300\n",
      "22/22 - 0s - loss: 0.0073 - accuracy: 0.9971 - val_loss: 2.7288 - val_accuracy: 0.5876 - 147ms/epoch - 7ms/step\n",
      "Epoch 79/300\n",
      "22/22 - 0s - loss: 0.0070 - accuracy: 0.9971 - val_loss: 2.7479 - val_accuracy: 0.5876 - 154ms/epoch - 7ms/step\n",
      "Epoch 80/300\n",
      "22/22 - 0s - loss: 0.0069 - accuracy: 0.9971 - val_loss: 2.7720 - val_accuracy: 0.5876 - 139ms/epoch - 6ms/step\n",
      "Epoch 81/300\n",
      "22/22 - 0s - loss: 0.0066 - accuracy: 0.9971 - val_loss: 2.7867 - val_accuracy: 0.5896 - 138ms/epoch - 6ms/step\n",
      "Epoch 82/300\n",
      "22/22 - 0s - loss: 0.0067 - accuracy: 0.9971 - val_loss: 2.8077 - val_accuracy: 0.5896 - 143ms/epoch - 6ms/step\n",
      "Epoch 83/300\n",
      "22/22 - 0s - loss: 0.0062 - accuracy: 0.9971 - val_loss: 2.8230 - val_accuracy: 0.5837 - 157ms/epoch - 7ms/step\n",
      "Epoch 84/300\n",
      "22/22 - 0s - loss: 0.0063 - accuracy: 0.9971 - val_loss: 2.8444 - val_accuracy: 0.5896 - 147ms/epoch - 7ms/step\n",
      "Epoch 85/300\n",
      "22/22 - 0s - loss: 0.0062 - accuracy: 0.9971 - val_loss: 2.8651 - val_accuracy: 0.5896 - 146ms/epoch - 7ms/step\n",
      "Epoch 86/300\n",
      "22/22 - 0s - loss: 0.0062 - accuracy: 0.9957 - val_loss: 2.8950 - val_accuracy: 0.5896 - 143ms/epoch - 7ms/step\n",
      "Epoch 87/300\n",
      "22/22 - 0s - loss: 0.0058 - accuracy: 0.9971 - val_loss: 2.9153 - val_accuracy: 0.5876 - 134ms/epoch - 6ms/step\n",
      "Epoch 88/300\n",
      "22/22 - 0s - loss: 0.0060 - accuracy: 0.9971 - val_loss: 2.9265 - val_accuracy: 0.5876 - 144ms/epoch - 7ms/step\n",
      "Epoch 89/300\n",
      "22/22 - 0s - loss: 0.0053 - accuracy: 0.9986 - val_loss: 2.9574 - val_accuracy: 0.5896 - 137ms/epoch - 6ms/step\n",
      "Epoch 90/300\n",
      "22/22 - 0s - loss: 0.0056 - accuracy: 0.9971 - val_loss: 2.9765 - val_accuracy: 0.5896 - 137ms/epoch - 6ms/step\n",
      "Epoch 91/300\n",
      "22/22 - 0s - loss: 0.0055 - accuracy: 0.9986 - val_loss: 2.9857 - val_accuracy: 0.5876 - 140ms/epoch - 6ms/step\n",
      "Epoch 92/300\n",
      "22/22 - 0s - loss: 0.0050 - accuracy: 0.9986 - val_loss: 3.0041 - val_accuracy: 0.5876 - 142ms/epoch - 6ms/step\n",
      "Epoch 93/300\n",
      "22/22 - 0s - loss: 0.0051 - accuracy: 0.9986 - val_loss: 3.0153 - val_accuracy: 0.5837 - 147ms/epoch - 7ms/step\n",
      "Epoch 94/300\n",
      "22/22 - 0s - loss: 0.0050 - accuracy: 0.9957 - val_loss: 3.0518 - val_accuracy: 0.5956 - 143ms/epoch - 7ms/step\n",
      "Epoch 95/300\n",
      "22/22 - 0s - loss: 0.0047 - accuracy: 0.9971 - val_loss: 3.0554 - val_accuracy: 0.5896 - 151ms/epoch - 7ms/step\n",
      "Epoch 96/300\n",
      "22/22 - 0s - loss: 0.0051 - accuracy: 0.9971 - val_loss: 3.0813 - val_accuracy: 0.5876 - 148ms/epoch - 7ms/step\n",
      "Epoch 97/300\n",
      "22/22 - 0s - loss: 0.0050 - accuracy: 0.9986 - val_loss: 3.0812 - val_accuracy: 0.5876 - 140ms/epoch - 6ms/step\n",
      "Epoch 98/300\n",
      "22/22 - 0s - loss: 0.0044 - accuracy: 0.9986 - val_loss: 3.1020 - val_accuracy: 0.5876 - 144ms/epoch - 7ms/step\n",
      "Epoch 99/300\n",
      "22/22 - 0s - loss: 0.0044 - accuracy: 0.9971 - val_loss: 3.1233 - val_accuracy: 0.5896 - 137ms/epoch - 6ms/step\n",
      "Epoch 100/300\n",
      "22/22 - 0s - loss: 0.0047 - accuracy: 0.9986 - val_loss: 3.1328 - val_accuracy: 0.5896 - 142ms/epoch - 6ms/step\n",
      "Epoch 101/300\n",
      "22/22 - 0s - loss: 0.0040 - accuracy: 0.9986 - val_loss: 3.1568 - val_accuracy: 0.5956 - 137ms/epoch - 6ms/step\n",
      "Epoch 102/300\n",
      "22/22 - 0s - loss: 0.0041 - accuracy: 0.9986 - val_loss: 3.1718 - val_accuracy: 0.5896 - 139ms/epoch - 6ms/step\n",
      "Epoch 103/300\n",
      "22/22 - 0s - loss: 0.0041 - accuracy: 0.9986 - val_loss: 3.1834 - val_accuracy: 0.5916 - 145ms/epoch - 7ms/step\n",
      "Epoch 104/300\n",
      "22/22 - 0s - loss: 0.0039 - accuracy: 0.9986 - val_loss: 3.2036 - val_accuracy: 0.5916 - 142ms/epoch - 6ms/step\n",
      "Epoch 105/300\n",
      "22/22 - 0s - loss: 0.0041 - accuracy: 0.9986 - val_loss: 3.2096 - val_accuracy: 0.5817 - 139ms/epoch - 6ms/step\n",
      "Epoch 106/300\n",
      "22/22 - 0s - loss: 0.0047 - accuracy: 0.9971 - val_loss: 3.2404 - val_accuracy: 0.5936 - 145ms/epoch - 7ms/step\n",
      "Epoch 107/300\n",
      "22/22 - 0s - loss: 0.0037 - accuracy: 0.9971 - val_loss: 3.2519 - val_accuracy: 0.5916 - 138ms/epoch - 6ms/step\n",
      "Epoch 108/300\n",
      "22/22 - 0s - loss: 0.0038 - accuracy: 0.9986 - val_loss: 3.2565 - val_accuracy: 0.5896 - 141ms/epoch - 6ms/step\n",
      "Epoch 109/300\n",
      "22/22 - 0s - loss: 0.0037 - accuracy: 0.9986 - val_loss: 3.2717 - val_accuracy: 0.5896 - 147ms/epoch - 7ms/step\n",
      "Epoch 110/300\n",
      "22/22 - 0s - loss: 0.0037 - accuracy: 0.9971 - val_loss: 3.2967 - val_accuracy: 0.5896 - 144ms/epoch - 7ms/step\n",
      "Epoch 111/300\n",
      "22/22 - 0s - loss: 0.0035 - accuracy: 0.9971 - val_loss: 3.3040 - val_accuracy: 0.5896 - 148ms/epoch - 7ms/step\n",
      "Epoch 112/300\n",
      "22/22 - 0s - loss: 0.0038 - accuracy: 0.9986 - val_loss: 3.3138 - val_accuracy: 0.5876 - 149ms/epoch - 7ms/step\n",
      "Epoch 113/300\n",
      "22/22 - 0s - loss: 0.0035 - accuracy: 0.9986 - val_loss: 3.3272 - val_accuracy: 0.5896 - 146ms/epoch - 7ms/step\n",
      "Epoch 114/300\n",
      "22/22 - 0s - loss: 0.0034 - accuracy: 0.9971 - val_loss: 3.3519 - val_accuracy: 0.5896 - 143ms/epoch - 6ms/step\n",
      "Epoch 115/300\n",
      "22/22 - 0s - loss: 0.0034 - accuracy: 0.9986 - val_loss: 3.3674 - val_accuracy: 0.5896 - 143ms/epoch - 7ms/step\n",
      "Epoch 116/300\n",
      "22/22 - 0s - loss: 0.0035 - accuracy: 0.9971 - val_loss: 3.3785 - val_accuracy: 0.5896 - 146ms/epoch - 7ms/step\n",
      "Epoch 117/300\n",
      "22/22 - 0s - loss: 0.0035 - accuracy: 0.9986 - val_loss: 3.3839 - val_accuracy: 0.5857 - 149ms/epoch - 7ms/step\n",
      "Epoch 118/300\n",
      "22/22 - 0s - loss: 0.0033 - accuracy: 0.9986 - val_loss: 3.4027 - val_accuracy: 0.5857 - 143ms/epoch - 7ms/step\n",
      "Epoch 119/300\n",
      "22/22 - 0s - loss: 0.0033 - accuracy: 0.9986 - val_loss: 3.4150 - val_accuracy: 0.5857 - 154ms/epoch - 7ms/step\n",
      "Epoch 120/300\n",
      "22/22 - 0s - loss: 0.0032 - accuracy: 0.9986 - val_loss: 3.4444 - val_accuracy: 0.5876 - 137ms/epoch - 6ms/step\n",
      "Epoch 121/300\n",
      "22/22 - 0s - loss: 0.0033 - accuracy: 0.9971 - val_loss: 3.4567 - val_accuracy: 0.5896 - 141ms/epoch - 6ms/step\n",
      "Epoch 122/300\n",
      "22/22 - 0s - loss: 0.0032 - accuracy: 0.9986 - val_loss: 3.4575 - val_accuracy: 0.5876 - 139ms/epoch - 6ms/step\n",
      "Epoch 123/300\n",
      "22/22 - 0s - loss: 0.0031 - accuracy: 0.9986 - val_loss: 3.4731 - val_accuracy: 0.5857 - 135ms/epoch - 6ms/step\n",
      "Epoch 124/300\n",
      "22/22 - 0s - loss: 0.0031 - accuracy: 0.9971 - val_loss: 3.4890 - val_accuracy: 0.5857 - 147ms/epoch - 7ms/step\n",
      "Epoch 125/300\n",
      "22/22 - 0s - loss: 0.0032 - accuracy: 0.9986 - val_loss: 3.4999 - val_accuracy: 0.5857 - 142ms/epoch - 6ms/step\n",
      "Epoch 126/300\n",
      "22/22 - 0s - loss: 0.0035 - accuracy: 0.9971 - val_loss: 3.5074 - val_accuracy: 0.5857 - 142ms/epoch - 6ms/step\n",
      "Epoch 127/300\n",
      "22/22 - 0s - loss: 0.0030 - accuracy: 0.9986 - val_loss: 3.5211 - val_accuracy: 0.5857 - 145ms/epoch - 7ms/step\n",
      "Epoch 128/300\n",
      "22/22 - 0s - loss: 0.0030 - accuracy: 0.9986 - val_loss: 3.5305 - val_accuracy: 0.5857 - 140ms/epoch - 6ms/step\n",
      "Epoch 129/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 3.5583 - val_accuracy: 0.5857 - 138ms/epoch - 6ms/step\n",
      "Epoch 130/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 3.5629 - val_accuracy: 0.5857 - 142ms/epoch - 6ms/step\n",
      "Epoch 131/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 3.5738 - val_accuracy: 0.5857 - 158ms/epoch - 7ms/step\n",
      "Epoch 132/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 3.5917 - val_accuracy: 0.5857 - 166ms/epoch - 8ms/step\n",
      "Epoch 133/300\n",
      "22/22 - 0s - loss: 0.0031 - accuracy: 0.9986 - val_loss: 3.5921 - val_accuracy: 0.5896 - 160ms/epoch - 7ms/step\n",
      "Epoch 134/300\n",
      "22/22 - 0s - loss: 0.0031 - accuracy: 0.9986 - val_loss: 3.6013 - val_accuracy: 0.5896 - 147ms/epoch - 7ms/step\n",
      "Epoch 135/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 3.6290 - val_accuracy: 0.5817 - 144ms/epoch - 7ms/step\n",
      "Epoch 136/300\n",
      "22/22 - 0s - loss: 0.0031 - accuracy: 0.9971 - val_loss: 3.6269 - val_accuracy: 0.5837 - 145ms/epoch - 7ms/step\n",
      "Epoch 137/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 3.6459 - val_accuracy: 0.5857 - 148ms/epoch - 7ms/step\n",
      "Epoch 138/300\n",
      "22/22 - 0s - loss: 0.0033 - accuracy: 0.9971 - val_loss: 3.6524 - val_accuracy: 0.5837 - 148ms/epoch - 7ms/step\n",
      "Epoch 139/300\n",
      "22/22 - 0s - loss: 0.0030 - accuracy: 0.9986 - val_loss: 3.6831 - val_accuracy: 0.5797 - 152ms/epoch - 7ms/step\n",
      "Epoch 140/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.6616 - val_accuracy: 0.5857 - 146ms/epoch - 7ms/step\n",
      "Epoch 141/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 3.6733 - val_accuracy: 0.5896 - 149ms/epoch - 7ms/step\n",
      "Epoch 142/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9986 - val_loss: 3.6850 - val_accuracy: 0.5857 - 147ms/epoch - 7ms/step\n",
      "Epoch 143/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 3.7008 - val_accuracy: 0.5857 - 150ms/epoch - 7ms/step\n",
      "Epoch 144/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 3.7209 - val_accuracy: 0.5837 - 139ms/epoch - 6ms/step\n",
      "Epoch 145/300\n",
      "22/22 - 0s - loss: 0.0033 - accuracy: 0.9971 - val_loss: 3.7131 - val_accuracy: 0.5896 - 153ms/epoch - 7ms/step\n",
      "Epoch 146/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 3.7431 - val_accuracy: 0.5817 - 158ms/epoch - 7ms/step\n",
      "Epoch 147/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 3.7500 - val_accuracy: 0.5857 - 147ms/epoch - 7ms/step\n",
      "Epoch 148/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9971 - val_loss: 3.7479 - val_accuracy: 0.5857 - 151ms/epoch - 7ms/step\n",
      "Epoch 149/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 3.7570 - val_accuracy: 0.5837 - 146ms/epoch - 7ms/step\n",
      "Epoch 150/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 3.7856 - val_accuracy: 0.5817 - 151ms/epoch - 7ms/step\n",
      "Epoch 151/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 3.7908 - val_accuracy: 0.5857 - 146ms/epoch - 7ms/step\n",
      "Epoch 152/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9971 - val_loss: 3.8048 - val_accuracy: 0.5857 - 147ms/epoch - 7ms/step\n",
      "Epoch 153/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 3.8059 - val_accuracy: 0.5837 - 148ms/epoch - 7ms/step\n",
      "Epoch 154/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 3.8142 - val_accuracy: 0.5837 - 152ms/epoch - 7ms/step\n",
      "Epoch 155/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 3.8264 - val_accuracy: 0.5837 - 141ms/epoch - 6ms/step\n",
      "Epoch 156/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 3.8370 - val_accuracy: 0.5837 - 144ms/epoch - 7ms/step\n",
      "Epoch 157/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9986 - val_loss: 3.8449 - val_accuracy: 0.5837 - 148ms/epoch - 7ms/step\n",
      "Epoch 158/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9971 - val_loss: 3.8537 - val_accuracy: 0.5837 - 151ms/epoch - 7ms/step\n",
      "Epoch 159/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 3.8572 - val_accuracy: 0.5857 - 159ms/epoch - 7ms/step\n",
      "Epoch 160/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 3.8661 - val_accuracy: 0.5837 - 144ms/epoch - 7ms/step\n",
      "Epoch 161/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9971 - val_loss: 3.8890 - val_accuracy: 0.5876 - 147ms/epoch - 7ms/step\n",
      "Epoch 162/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 3.8827 - val_accuracy: 0.5857 - 152ms/epoch - 7ms/step\n",
      "Epoch 163/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9971 - val_loss: 3.9049 - val_accuracy: 0.5876 - 154ms/epoch - 7ms/step\n",
      "Epoch 164/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9971 - val_loss: 3.8889 - val_accuracy: 0.5857 - 153ms/epoch - 7ms/step\n",
      "Epoch 165/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 3.9012 - val_accuracy: 0.5837 - 144ms/epoch - 7ms/step\n",
      "Epoch 166/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9971 - val_loss: 3.9322 - val_accuracy: 0.5857 - 145ms/epoch - 7ms/step\n",
      "Epoch 167/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 3.9211 - val_accuracy: 0.5837 - 154ms/epoch - 7ms/step\n",
      "Epoch 168/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 3.9378 - val_accuracy: 0.5857 - 150ms/epoch - 7ms/step\n",
      "Epoch 169/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 3.9370 - val_accuracy: 0.5837 - 141ms/epoch - 6ms/step\n",
      "Epoch 170/300\n",
      "22/22 - 0s - loss: 0.0033 - accuracy: 0.9971 - val_loss: 3.9654 - val_accuracy: 0.5857 - 150ms/epoch - 7ms/step\n",
      "Epoch 171/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9971 - val_loss: 3.9688 - val_accuracy: 0.5876 - 147ms/epoch - 7ms/step\n",
      "Epoch 172/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 3.9627 - val_accuracy: 0.5857 - 158ms/epoch - 7ms/step\n",
      "Epoch 173/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9986 - val_loss: 3.9636 - val_accuracy: 0.5876 - 157ms/epoch - 7ms/step\n",
      "Epoch 174/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 3.9932 - val_accuracy: 0.5876 - 150ms/epoch - 7ms/step\n",
      "Epoch 175/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9986 - val_loss: 3.9979 - val_accuracy: 0.5876 - 149ms/epoch - 7ms/step\n",
      "Epoch 176/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 3.9887 - val_accuracy: 0.5876 - 148ms/epoch - 7ms/step\n",
      "Epoch 177/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9971 - val_loss: 4.0103 - val_accuracy: 0.5876 - 150ms/epoch - 7ms/step\n",
      "Epoch 178/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.0052 - val_accuracy: 0.5857 - 148ms/epoch - 7ms/step\n",
      "Epoch 179/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.0282 - val_accuracy: 0.5876 - 142ms/epoch - 6ms/step\n",
      "Epoch 180/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.0459 - val_accuracy: 0.5857 - 152ms/epoch - 7ms/step\n",
      "Epoch 181/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.0345 - val_accuracy: 0.5837 - 147ms/epoch - 7ms/step\n",
      "Epoch 182/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.0451 - val_accuracy: 0.5837 - 142ms/epoch - 6ms/step\n",
      "Epoch 183/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.0543 - val_accuracy: 0.5837 - 151ms/epoch - 7ms/step\n",
      "Epoch 184/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 4.1045 - val_accuracy: 0.5717 - 151ms/epoch - 7ms/step\n",
      "Epoch 185/300\n",
      "22/22 - 0s - loss: 0.0034 - accuracy: 0.9971 - val_loss: 4.0676 - val_accuracy: 0.5837 - 165ms/epoch - 7ms/step\n",
      "Epoch 186/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.0871 - val_accuracy: 0.5817 - 160ms/epoch - 7ms/step\n",
      "Epoch 187/300\n",
      "22/22 - 0s - loss: 0.0033 - accuracy: 0.9986 - val_loss: 4.1455 - val_accuracy: 0.5717 - 151ms/epoch - 7ms/step\n",
      "Epoch 188/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.0799 - val_accuracy: 0.5857 - 143ms/epoch - 7ms/step\n",
      "Epoch 189/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 4.0908 - val_accuracy: 0.5817 - 149ms/epoch - 7ms/step\n",
      "Epoch 190/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9971 - val_loss: 4.1048 - val_accuracy: 0.5817 - 143ms/epoch - 7ms/step\n",
      "Epoch 191/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.1004 - val_accuracy: 0.5817 - 141ms/epoch - 6ms/step\n",
      "Epoch 192/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.1155 - val_accuracy: 0.5817 - 143ms/epoch - 6ms/step\n",
      "Epoch 193/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.1261 - val_accuracy: 0.5857 - 150ms/epoch - 7ms/step\n",
      "Epoch 194/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.1334 - val_accuracy: 0.5837 - 147ms/epoch - 7ms/step\n",
      "Epoch 195/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 4.1316 - val_accuracy: 0.5817 - 143ms/epoch - 6ms/step\n",
      "Epoch 196/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.1368 - val_accuracy: 0.5817 - 148ms/epoch - 7ms/step\n",
      "Epoch 197/300\n",
      "22/22 - 0s - loss: 0.0030 - accuracy: 0.9986 - val_loss: 4.1931 - val_accuracy: 0.5737 - 140ms/epoch - 6ms/step\n",
      "Epoch 198/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9971 - val_loss: 4.1315 - val_accuracy: 0.5837 - 146ms/epoch - 7ms/step\n",
      "Epoch 199/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.1511 - val_accuracy: 0.5837 - 155ms/epoch - 7ms/step\n",
      "Epoch 200/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9971 - val_loss: 4.1592 - val_accuracy: 0.5837 - 159ms/epoch - 7ms/step\n",
      "Epoch 201/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.1736 - val_accuracy: 0.5876 - 165ms/epoch - 7ms/step\n",
      "Epoch 202/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.1801 - val_accuracy: 0.5837 - 177ms/epoch - 8ms/step\n",
      "Epoch 203/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9971 - val_loss: 4.2087 - val_accuracy: 0.5817 - 154ms/epoch - 7ms/step\n",
      "Epoch 204/300\n",
      "22/22 - 0s - loss: 0.0032 - accuracy: 0.9971 - val_loss: 4.1756 - val_accuracy: 0.5817 - 164ms/epoch - 7ms/step\n",
      "Epoch 205/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.1995 - val_accuracy: 0.5837 - 164ms/epoch - 7ms/step\n",
      "Epoch 206/300\n",
      "22/22 - 0s - loss: 0.0030 - accuracy: 0.9971 - val_loss: 4.1719 - val_accuracy: 0.5797 - 170ms/epoch - 8ms/step\n",
      "Epoch 207/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9971 - val_loss: 4.1973 - val_accuracy: 0.5876 - 145ms/epoch - 7ms/step\n",
      "Epoch 208/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.2181 - val_accuracy: 0.5857 - 144ms/epoch - 7ms/step\n",
      "Epoch 209/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.2211 - val_accuracy: 0.5837 - 148ms/epoch - 7ms/step\n",
      "Epoch 210/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9971 - val_loss: 4.2105 - val_accuracy: 0.5817 - 143ms/epoch - 7ms/step\n",
      "Epoch 211/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9971 - val_loss: 4.2388 - val_accuracy: 0.5857 - 164ms/epoch - 7ms/step\n",
      "Epoch 212/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.2659 - val_accuracy: 0.5777 - 149ms/epoch - 7ms/step\n",
      "Epoch 213/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.2375 - val_accuracy: 0.5817 - 147ms/epoch - 7ms/step\n",
      "Epoch 214/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.2406 - val_accuracy: 0.5837 - 137ms/epoch - 6ms/step\n",
      "Epoch 215/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.2509 - val_accuracy: 0.5857 - 141ms/epoch - 6ms/step\n",
      "Epoch 216/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 4.2427 - val_accuracy: 0.5817 - 151ms/epoch - 7ms/step\n",
      "Epoch 217/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.2763 - val_accuracy: 0.5837 - 146ms/epoch - 7ms/step\n",
      "Epoch 218/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.2730 - val_accuracy: 0.5857 - 157ms/epoch - 7ms/step\n",
      "Epoch 219/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 4.2558 - val_accuracy: 0.5797 - 144ms/epoch - 7ms/step\n",
      "Epoch 220/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.2695 - val_accuracy: 0.5857 - 159ms/epoch - 7ms/step\n",
      "Epoch 221/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.3018 - val_accuracy: 0.5817 - 145ms/epoch - 7ms/step\n",
      "Epoch 222/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9971 - val_loss: 4.2845 - val_accuracy: 0.5857 - 147ms/epoch - 7ms/step\n",
      "Epoch 223/300\n",
      "22/22 - 0s - loss: 0.0030 - accuracy: 0.9971 - val_loss: 4.3197 - val_accuracy: 0.5777 - 144ms/epoch - 7ms/step\n",
      "Epoch 224/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.3241 - val_accuracy: 0.5777 - 149ms/epoch - 7ms/step\n",
      "Epoch 225/300\n",
      "22/22 - 0s - loss: 0.0020 - accuracy: 0.9986 - val_loss: 4.2927 - val_accuracy: 0.5777 - 154ms/epoch - 7ms/step\n",
      "Epoch 226/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.2977 - val_accuracy: 0.5857 - 152ms/epoch - 7ms/step\n",
      "Epoch 227/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.2970 - val_accuracy: 0.5837 - 141ms/epoch - 6ms/step\n",
      "Epoch 228/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.3376 - val_accuracy: 0.5797 - 148ms/epoch - 7ms/step\n",
      "Epoch 229/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.3393 - val_accuracy: 0.5817 - 150ms/epoch - 7ms/step\n",
      "Epoch 230/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.3332 - val_accuracy: 0.5797 - 149ms/epoch - 7ms/step\n",
      "Epoch 231/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.3458 - val_accuracy: 0.5797 - 149ms/epoch - 7ms/step\n",
      "Epoch 232/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9971 - val_loss: 4.3490 - val_accuracy: 0.5817 - 147ms/epoch - 7ms/step\n",
      "Epoch 233/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 4.3866 - val_accuracy: 0.5777 - 144ms/epoch - 7ms/step\n",
      "Epoch 234/300\n",
      "22/22 - 0s - loss: 0.0035 - accuracy: 0.9971 - val_loss: 4.3290 - val_accuracy: 0.5797 - 143ms/epoch - 6ms/step\n",
      "Epoch 235/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9971 - val_loss: 4.3526 - val_accuracy: 0.5797 - 144ms/epoch - 7ms/step\n",
      "Epoch 236/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9971 - val_loss: 4.3536 - val_accuracy: 0.5797 - 160ms/epoch - 7ms/step\n",
      "Epoch 237/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 4.3792 - val_accuracy: 0.5797 - 169ms/epoch - 8ms/step\n",
      "Epoch 238/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9986 - val_loss: 4.3436 - val_accuracy: 0.5757 - 151ms/epoch - 7ms/step\n",
      "Epoch 239/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.3866 - val_accuracy: 0.5797 - 143ms/epoch - 6ms/step\n",
      "Epoch 240/300\n",
      "22/22 - 0s - loss: 0.0030 - accuracy: 0.9986 - val_loss: 4.4405 - val_accuracy: 0.5717 - 138ms/epoch - 6ms/step\n",
      "Epoch 241/300\n",
      "22/22 - 0s - loss: 0.0020 - accuracy: 0.9986 - val_loss: 4.3750 - val_accuracy: 0.5837 - 137ms/epoch - 6ms/step\n",
      "Epoch 242/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.3612 - val_accuracy: 0.5737 - 142ms/epoch - 6ms/step\n",
      "Epoch 243/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.3943 - val_accuracy: 0.5797 - 136ms/epoch - 6ms/step\n",
      "Epoch 244/300\n",
      "22/22 - 0s - loss: 0.0021 - accuracy: 0.9986 - val_loss: 4.3805 - val_accuracy: 0.5817 - 148ms/epoch - 7ms/step\n",
      "Epoch 245/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.3872 - val_accuracy: 0.5817 - 151ms/epoch - 7ms/step\n",
      "Epoch 246/300\n",
      "22/22 - 0s - loss: 0.0021 - accuracy: 0.9986 - val_loss: 4.4026 - val_accuracy: 0.5797 - 138ms/epoch - 6ms/step\n",
      "Epoch 247/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.4082 - val_accuracy: 0.5797 - 147ms/epoch - 7ms/step\n",
      "Epoch 248/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.4210 - val_accuracy: 0.5797 - 141ms/epoch - 6ms/step\n",
      "Epoch 249/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.4219 - val_accuracy: 0.5797 - 141ms/epoch - 6ms/step\n",
      "Epoch 250/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.4284 - val_accuracy: 0.5797 - 141ms/epoch - 6ms/step\n",
      "Epoch 251/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.4163 - val_accuracy: 0.5817 - 141ms/epoch - 6ms/step\n",
      "Epoch 252/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.4151 - val_accuracy: 0.5817 - 160ms/epoch - 7ms/step\n",
      "Epoch 253/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.4322 - val_accuracy: 0.5797 - 149ms/epoch - 7ms/step\n",
      "Epoch 254/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9971 - val_loss: 4.4610 - val_accuracy: 0.5777 - 148ms/epoch - 7ms/step\n",
      "Epoch 255/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 4.4958 - val_accuracy: 0.5757 - 140ms/epoch - 6ms/step\n",
      "Epoch 256/300\n",
      "22/22 - 0s - loss: 0.0021 - accuracy: 0.9986 - val_loss: 4.4476 - val_accuracy: 0.5797 - 138ms/epoch - 6ms/step\n",
      "Epoch 257/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.4468 - val_accuracy: 0.5797 - 135ms/epoch - 6ms/step\n",
      "Epoch 258/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.4658 - val_accuracy: 0.5837 - 134ms/epoch - 6ms/step\n",
      "Epoch 259/300\n",
      "22/22 - 0s - loss: 0.0028 - accuracy: 0.9986 - val_loss: 4.4855 - val_accuracy: 0.5797 - 143ms/epoch - 6ms/step\n",
      "Epoch 260/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.4692 - val_accuracy: 0.5817 - 148ms/epoch - 7ms/step\n",
      "Epoch 261/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 4.4636 - val_accuracy: 0.5817 - 143ms/epoch - 7ms/step\n",
      "Epoch 262/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.4813 - val_accuracy: 0.5817 - 139ms/epoch - 6ms/step\n",
      "Epoch 263/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.4882 - val_accuracy: 0.5817 - 137ms/epoch - 6ms/step\n",
      "Epoch 264/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.4893 - val_accuracy: 0.5817 - 138ms/epoch - 6ms/step\n",
      "Epoch 265/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.5128 - val_accuracy: 0.5797 - 144ms/epoch - 7ms/step\n",
      "Epoch 266/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.5160 - val_accuracy: 0.5797 - 151ms/epoch - 7ms/step\n",
      "Epoch 267/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.4913 - val_accuracy: 0.5817 - 134ms/epoch - 6ms/step\n",
      "Epoch 268/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.5020 - val_accuracy: 0.5817 - 139ms/epoch - 6ms/step\n",
      "Epoch 269/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.5094 - val_accuracy: 0.5777 - 138ms/epoch - 6ms/step\n",
      "Epoch 270/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.5230 - val_accuracy: 0.5777 - 142ms/epoch - 6ms/step\n",
      "Epoch 271/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 4.5451 - val_accuracy: 0.5717 - 154ms/epoch - 7ms/step\n",
      "Epoch 272/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.5001 - val_accuracy: 0.5757 - 139ms/epoch - 6ms/step\n",
      "Epoch 273/300\n",
      "22/22 - 0s - loss: 0.0031 - accuracy: 0.9971 - val_loss: 4.5625 - val_accuracy: 0.5717 - 138ms/epoch - 6ms/step\n",
      "Epoch 274/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.5157 - val_accuracy: 0.5797 - 148ms/epoch - 7ms/step\n",
      "Epoch 275/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9986 - val_loss: 4.5033 - val_accuracy: 0.5777 - 167ms/epoch - 8ms/step\n",
      "Epoch 276/300\n",
      "22/22 - 0s - loss: 0.0034 - accuracy: 0.9971 - val_loss: 4.5887 - val_accuracy: 0.5717 - 137ms/epoch - 6ms/step\n",
      "Epoch 277/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9971 - val_loss: 4.5101 - val_accuracy: 0.5797 - 138ms/epoch - 6ms/step\n",
      "Epoch 278/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.5246 - val_accuracy: 0.5817 - 149ms/epoch - 7ms/step\n",
      "Epoch 279/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.5158 - val_accuracy: 0.5797 - 144ms/epoch - 7ms/step\n",
      "Epoch 280/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.5452 - val_accuracy: 0.5757 - 158ms/epoch - 7ms/step\n",
      "Epoch 281/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9986 - val_loss: 4.5544 - val_accuracy: 0.5757 - 149ms/epoch - 7ms/step\n",
      "Epoch 282/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.5488 - val_accuracy: 0.5777 - 134ms/epoch - 6ms/step\n",
      "Epoch 283/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9986 - val_loss: 4.5284 - val_accuracy: 0.5777 - 139ms/epoch - 6ms/step\n",
      "Epoch 284/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9971 - val_loss: 4.5571 - val_accuracy: 0.5757 - 137ms/epoch - 6ms/step\n",
      "Epoch 285/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.5568 - val_accuracy: 0.5777 - 148ms/epoch - 7ms/step\n",
      "Epoch 286/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9986 - val_loss: 4.6005 - val_accuracy: 0.5717 - 161ms/epoch - 7ms/step\n",
      "Epoch 287/300\n",
      "22/22 - 0s - loss: 0.0027 - accuracy: 0.9971 - val_loss: 4.5546 - val_accuracy: 0.5777 - 151ms/epoch - 7ms/step\n",
      "Epoch 288/300\n",
      "22/22 - 0s - loss: 0.0021 - accuracy: 0.9986 - val_loss: 4.5810 - val_accuracy: 0.5777 - 155ms/epoch - 7ms/step\n",
      "Epoch 289/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9971 - val_loss: 4.5659 - val_accuracy: 0.5757 - 142ms/epoch - 6ms/step\n",
      "Epoch 290/300\n",
      "22/22 - 0s - loss: 0.0023 - accuracy: 0.9971 - val_loss: 4.5844 - val_accuracy: 0.5777 - 173ms/epoch - 8ms/step\n",
      "Epoch 291/300\n",
      "22/22 - 0s - loss: 0.0022 - accuracy: 0.9986 - val_loss: 4.6012 - val_accuracy: 0.5757 - 160ms/epoch - 7ms/step\n",
      "Epoch 292/300\n",
      "22/22 - 0s - loss: 0.0021 - accuracy: 0.9986 - val_loss: 4.6028 - val_accuracy: 0.5777 - 158ms/epoch - 7ms/step\n",
      "Epoch 293/300\n",
      "22/22 - 0s - loss: 0.0021 - accuracy: 0.9971 - val_loss: 4.6049 - val_accuracy: 0.5757 - 153ms/epoch - 7ms/step\n",
      "Epoch 294/300\n",
      "22/22 - 0s - loss: 0.0024 - accuracy: 0.9971 - val_loss: 4.6111 - val_accuracy: 0.5757 - 154ms/epoch - 7ms/step\n",
      "Epoch 295/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.6227 - val_accuracy: 0.5757 - 150ms/epoch - 7ms/step\n",
      "Epoch 296/300\n",
      "22/22 - 0s - loss: 0.0025 - accuracy: 0.9986 - val_loss: 4.5974 - val_accuracy: 0.5777 - 140ms/epoch - 6ms/step\n",
      "Epoch 297/300\n",
      "22/22 - 0s - loss: 0.0030 - accuracy: 0.9971 - val_loss: 4.6275 - val_accuracy: 0.5777 - 137ms/epoch - 6ms/step\n",
      "Epoch 298/300\n",
      "22/22 - 0s - loss: 0.0021 - accuracy: 0.9986 - val_loss: 4.6202 - val_accuracy: 0.5757 - 158ms/epoch - 7ms/step\n",
      "Epoch 299/300\n",
      "22/22 - 0s - loss: 0.0026 - accuracy: 0.9971 - val_loss: 4.6428 - val_accuracy: 0.5757 - 151ms/epoch - 7ms/step\n",
      "Epoch 300/300\n",
      "22/22 - 0s - loss: 0.0029 - accuracy: 0.9986 - val_loss: 4.5951 - val_accuracy: 0.5777 - 152ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "history = model.fit(training_padded, \n",
    "                    training_labels, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(testing_padded, testing_labels), \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##plot the scores from history\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying unseen sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "[[1.000000e+00]\n",
      " [2.313822e-04]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"the girl starting to fear snakes in the garden might be real\", \"game of thrones season finale showing this sunday night\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print(model.predict(padded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd53c7222885d7750057d794778faebdb531c8e31dbaca85af85a4aaf6256611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
